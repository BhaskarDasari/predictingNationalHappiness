---
title: "Predicting National Happiness"
author: "OJ Watson"
date: "3 August 2016" 
output: 
  html_document: 
    toc: yes
---
***

A general attempt/solution to the predicting national happiness meetup challenge. 

As wth most datasets a large portion of the solution is on cleaning the database to find suitable
indicators for the task at hand

For best results load this Rmd file into R studio and click 'Knit HTML'

# Acquiring necessary packages and setting up the workspace

``` {r setup, message = FALSE, warning = FALSE,results='hide'}

# Set working directory to where you have stored the data
setwd("C:/Users/Oliver/GoogleDrive/DataScience/HappinessProject")

# Install and load required packages
install.packages("countrycode",repos="http://cloud.r-project.org/")
install.packages("WDI",repos="http://cloud.r-project.org/")
install.packages("dplyr",repos="http://cloud.r-project.org/")
install.packages("car",repos="http://cloud.r-project.org/")
# Package for dealing with country iso character abbrevations
library(countrycode)
# Package for loading World Development Indicators
library(WDI)
# Package to help tackling the data munging
library(dplyr)
# Package for helping look at the cleaned data in a multivariate statistical way
library(car)

```

# Loading the datasets and exploring country names
First I will be looking at the country names included in the happiness dataset and checking them
against those used/available in the WDI dataset

``` {r load_countries_and_clean, message = FALSE, warning = FALSE}

## Load the hapiness dataset
load("happiness.RData")

## Vector of countries
countries <- happiness.df$Country

## Convert countries into iso2c for use with WDI package
iso2s <- countrycode::countrycode(countries,origin = "country.name",destination = "iso2c")

## Check for any country codes that were not matched correctly
incorrect_matches <- which(is.na(iso2s))

## Look up what this should have been
countries[incorrect_matches]

## Kosovo fails... Manually add
iso2s[77] <- "XK"

```


# Check that the iso2s correlate correctly with those in the WDI
I will then look at all the data from the WDI package for 2014-2016 (smaller task and liekly to have
better correlation with 2016 happiness). By looking at all the iso2cs from the WDI that match the happiness
dataset iso2cs we can then start to subset the data.

``` {r match_indicators, message = FALSE, warning = FALSE}

# First create vector of all indicators so we can use this in searching the WDI database
allIndicators <- WDI::WDIsearch()

# Grab all the data (takes a couple of mins)
all_from_WDI <- WDI::WDI(country="all", indicator=c(allIndicators[,1]),start=2014, end=2016)

# Grab the unique country iso2cs from WDI
iso2s_from_WDI <- unique(all_from_WDI$iso2c)

# See if all previous iso2s match
not.match <- which(is.na(match(iso2s,iso2s_from_WDI)))

# Clearly an issue with Taiwan so will exclude. 
iso2s <- iso2s[-not.match]

```


# Clean the dataset so we only have complete/near complete metrics for our countries for 2015
Through a series of subsetting the dataset, we can create a list of indicators that we can explore
for correlation with national happiness

``` {r clean_subset, message = FALSE, warning = FALSE}

# Look at only 2015
WDI_2015 <- all_from_WDI[all_from_WDI$year==2015,]

# Look at only countres we have from wikipedia
WDI_2015_Wiki <- WDI_2015[match(iso2s,WDI_2015$iso2c),]

# Find out which metrics we have for every country
metric.check <- lapply(WDI_2015_Wiki,FUN = is.na) %>% lapply(FUN = sum)

# Subset for the last time by by these metrics saying we need at least 50 datpoints for it to be useful
WDI_Final <- WDI_2015_Wiki[,which(metric.check<50)]

# Add happiness scores to the dataframe remebering to remove 
WDI_Final$Happiness <- as.numeric(happiness.df$Happiness.2016[-not.match])

# Change Indicators to things that humans understand by matching the indicator variables
indicator.pos <- match(names(WDI_Final)[4:42],allIndicators[,1])
names(WDI_Final)[4:42] <- allIndicators[indicator.pos,2]

```

# Look Around
We now have a dataframe with suitable indicators for 2015 for all countries. By now time was nearing up
so a simple exploraton of all the correlations was conducted before looking at those that correlated well.

``` {r multivariate_investigation,message = FALSE, warning = FALSE,results='hide'}

# Plot to a pdf (easier to view sequences of plots this way i feel)
pdf(file="MultivariateInvestigation.pdf")
for(i in 1:6){
car::scatterplotMatrix(WDI_Final[c(( ((i-1)*3) + 4 ):(((i-1)*3) + 6),43)])
}
dev.off()

# There is some stuff so let's fnd the best 5 or all above 0.6 R2
happiness.correlates <- sort(cor(WDI_Final[4:43],use="complete")[40,1:39])
best.correlates <- which(happiness.correlates>0.6)

# Save them
pdf(file="BestCorrelates.pdf")
for(i in 1:(length(best.correlates)/2)){
car::scatterplotMatrix(WDI_Final[as.numeric(c(best.correlates[(((i-1)*2)+1):(2*i)],43))])
}
dev.off()

## Et voila apparently people like money, growth and savings...
```

Obviously this is very brief so far, and coming up with more sophisticated metrics and testing of correlates
against bootstraps/leave one out vaidation methods would next happen. 


